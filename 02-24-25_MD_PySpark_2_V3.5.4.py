# -*- coding: utf-8 -*-
"""PySpark_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Zhxg5R9LVIvteQU7pMSuGPNQGQ8qkRdE
"""


import findspark
findspark.init()
import pyspark
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("Pyspark_2").getOrCreate()
print(spark.version)

data1 = [(1, 'Jay'), (2, 'Avi'), (3, 'Saint'), (4,'Jerome')]
columns = ['ID', 'Name']
df1=spark.createDataFrame(data1,columns)
df1.show()
data2 = [(5,'Mohan'),(6,'Teddy'), (7,'Leon'), (8,'Gustavo')]
df2=spark.createDataFrame(data2,columns)
df2.show()

from typing import Union
#Union

UnionDF=df1.union(df2)
UnionDF.show()

data = [("1", "john jones"),
    ("2", "tracey smith"),
    ("3", "amy sanders")]
columns = ["Seqno","Name"]
df=spark.createDataFrame(data,columns)

df.show()

data = [1,2,3,4,5,6,7,8,9,10,11,12]
rdd = spark.sparkContext.parallelize(data)
print(rdd)
print("Initial partition count:"+str(rdd.getNumPartitions()))